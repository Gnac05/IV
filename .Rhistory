install.packages(fGarch)
install.packages('fGarch')
#-------------------------------||-----------------------------------
if(!require('fGarch')) {
install.packages('fGarch')
library('fGarch')
}
library(timeSeries)
library('timeSeries')
library('fGarch')
## Parameter Estimation of Default GARCH(1,1) Model
set.seed(123)
fit = garchFit(~ garch(1, 1), data = garchSim(), trace = FALSE)
fit
data("EuStockMarkets")
fix(EuStockMarkets)
dataGMM = EuStockMarkets
CAC = dataGMM[,3]
plot(CAC)
r = diff(log(CAC))
plot(r)
## Parameter Estimation of Default GARCH(1,1) Model
set.seed(123)
fit = garchFit(~ garch(1, 1), data = r, trace = FALSE)
fit
## predict
predict(fit, n.ahead = 10)
predict(fit, n.ahead = 10, mse="uncond")
## predict with plotting: critical values = +/- 2
predict(fit, n.ahead = 10, plot=TRUE, crit_val = 2)
## include also VaR and ES at 5%
predict(fit, n.ahead = 10, plot=TRUE, crit_val = 2, p_loss = 0.05)
## predict with plotting: automatic critical values
## for different conditional distributions
set.seed(321)
fit2 = garchFit(~ garch(1, 1), data = garchSim(), trace=FALSE, cond.dist="sged")
## 95% confidence level
predict(fit2, n.ahead=20, plot=TRUE)
set.seed(444)
fit3 = garchFit(~ garch(1, 1), data = garchSim(), trace=FALSE, cond.dist="QMLE")
fit2 = garchFit(~ garch(1, 1), data = r, trace=TRUE, cond.dist="sged")
library(PerformanceAnalytics)
## Simple filter buy rule
library(quantmod)
getSymbols('MSFT')
price = Cl(MSFT) # close price
r = price/Lag(price) - 1 # price change (rendement)
delta = 0.005 # threshold
# Evaluation of this signal with the day trading
returnMSFT = (Cl(MSFT) - Op(MSFT))/Op(MSFT)
# RSI
day = 14
# Comparing rules
filter.signal <-c(0) # first date has no signal
rsi <- RSI(price, day)     #rsi is the lag of RSI
RSI.signal <- c()          #initialize vector
RSI.signal [1:day+1] <- 0  #0 because no signal until day+1
for (i in 2: length(price)){
if (r[i] > delta){
filter.signal[i]<- 1
} else
filter.signal[i]<- 0
}
filter.signal<-reclass(filter.signal,Cl(MSFT))
for (i in 2: length(price)){
if (r[i] > delta){
filter.signal[i]<- 1
} else
filter.signal[i]<- 0
}
filter.signal<-reclass(filter.signal,Cl(MSFT))
filter.trade <- Lag(filter.signal,1)
filter.ret <- returnMSFT*filter.trade
names(filter.ret) <- 'filter'
RSI.trade <- Lag(RSI.signal,1)
RSI.ret <- returnMSFT*RSI.trade
RSI.trade <- Lag(filter.signal,1)
RSI.ret <- returnMSFT*RSI.trade
names(RSI.ret) <- 'RSI'
retall <- cbind(filter.ret, RSI.ret)
charts.PerformanceSummary(retall,
main="filter v.s. RSI")
for (i in 2: length(price)){
if (r[i] > delta){
filter.signal[i]<- 1
} else
filter.signal[i]<- 0
}
filter.signal<-reclass(filter.signal,Cl(MSFT))
filter.trade <- Lag(filter.signal,1)
filter.ret <- returnMSFT*filter.trade
names(filter.ret) <- 'filter'
RSI.trade <- Lag(filter.signal,1)
RSI.trade <- Lag(RSI.signal,1)
RSI.ret <- returnMSFT*RSI.trade
filter.signal <-c(0) # first date has no signal
rsi <- RSI(price, day)     #rsi is the lag of RSI
RSI.signal <- c()          #initialize vector
RSI.signal [1:day+1] <- 0  #0 because no signal until day+1
for (i in 2: length(price)){
if (r[i] > delta){
filter.signal[i]<- 1
} else
filter.signal[i]<- 0
}
filter.signal<-reclass(filter.signal,Cl(MSFT))
for (i in (day+1): length(price)){
if (rsi[i] < 30){             #buy if rsi < 30
RSI.signal[i] <- 1
}else {                       #no trade all if rsi > 30
RSI.signal[i] <- 0
}
}
RSI.signal<-reclass(RSI.signal,Cl(MSFT))
filter.trade <- Lag(filter.signal,1)
filter.ret <- returnMSFT*filter.trade
names(filter.ret) <- 'filter'
RSI.trade <- Lag(RSI.signal,1)
RSI.ret <- returnMSFT*RSI.trade
names(RSI.ret) <- 'RSI'
retall <- cbind(filter.ret, RSI.ret)
charts.PerformanceSummary(retall,
main="filter v.s. RSI")
delta<-0.005
r <- price/Lag(price) - 1
n <- 14
rsi <- RSI(price, n)
signal <-c()
signal[1:n] <-0
for (i in (n+1):length(price)){
if (r[i] > delta){
signal[i]<- 1
} else if (rsi[i] > 70){
signal[i]<- -1
} else
signal[i]<- 0
}
signal<-reclass(signal,price)
EMA.RSI.trade <- Lag(signal)
EMA.RSI.ret<- returnMSFT*EMA.RSI.trade
names(EMA.RSI.ret) <- 'Combined'
retall <- cbind(filter.ret, RSI.ret, EMA.RSI.ret)
charts.PerformanceSummary(retall,
main="Thee Comparisons",
colorset=bluefocus)
# Trading Size
signal <- c()
signal[1:(day+1)] <- 0
for (i in (day+1): length(price)){
if (rsi[i] < 30){  #buy one more unit
signal[i] <- signal[i-1]+1
} else if (rsi[i] < 50){  #no change
signal[i] <- signal[i-1]
} else {         #sell all
signal[i] <- 0
}
}
signal<-reclass(signal,price)
signal <- c()
signal[1:(day+1)] <- 0
for (i in (day+1): length(price)){
if (rsi[i] < 30){  #buy one more unit
signal[i] <- signal[i-1]+1
} else if (rsi[i] < 50){  #no change
signal[i] <- signal[i-1]
} else {         #sell all
signal[i] <- 0
}
}
signal<-reclass(signal,price)
Close <- Cl(MSFT)
Open <- Op(MSFT)
trade <- Lag(signal)
for (i in (day+1):length(price)){
profit[i] <- qty * trade[i] * (Close[i] - Open[i])
wealth[i] <- wealth[i-1] + profit[i]
return[i] <- (wealth[i] / wealth[i-1]) -1
}
# Trading Size
signal <- c()
signal[1:(day+1)] <- 0
for (i in (day+1): length(price)){
if (rsi[i] < 30){  #buy one more unit
signal[i] <- signal[i-1]+1
} else if (rsi[i] < 50){  #no change
signal[i] <- signal[i-1]
} else {         #sell all
signal[i] <- 0
}
}
signal<-reclass(signal,price)
qty <-1000 #trading size
wealth <-c()
wealth[1:(day+1)] <- 1000000
profit <-c()
profit[1:(day+1)] <- 0
return<-c()
return[1:(day+1)] <- 0
Close <- Cl(MSFT)
Open <- Op(MSFT)
trade <- Lag(signal)
for (i in (day+1):length(price)){
profit[i] <- qty * trade[i] * (Close[i] - Open[i])
wealth[i] <- wealth[i-1] + profit[i]
return[i] <- (wealth[i] / wealth[i-1]) -1
}
ret<-reclass(return,price)
charts.PerformanceSummary(ret, main="Trade Size")
yhat <- ols$fitted
library(foreign)
Panel <- read.dta("http://dss.princeton.edu/training/Panel101.dta")
####---FIXED EFFECTS MODEL---####
library(gplots)
ols <-lm(y ~ x1, data=Panel)
summary(ols)
yhat <- ols$fitted
yhat
plot(yhat)
plot(yhat,type = 'l')
plot(Panel$x1, Panel$y, pch=19, xlab="x1", ylab="y")
abline(lm(Panel$y~Panel$x1),lwd=3, col="red")
fixed.dum <-lm(y ~ x1 + factor(country) - 1, data=Panel)
summary(fixed.dum)
fixed.dum <-lm(y ~ x1 + factor(country) - 1, data=Panel)
summary(fixed.dum)
yhat <- fixed.dum$fitted
scatterplot(yhat~Panel$x1|Panel$country, boxplots=FALSE, xlab="x1", ylab="yhat",smooth=FALSE)
abline(lm(Panel$y~Panel$x1),lwd=3, col="red")
library(car)
scatterplot(yhat~Panel$x1|Panel$country, boxplots=FALSE, xlab="x1", ylab="yhat",smooth=FALSE)
abline(lm(Panel$y~Panel$x1),lwd=3, col="red")
install.packages(apsrtable)
install.packages('apsrtable')
install.packages('apsrtable')
install.packages('devtools')
devtools::install_github("fsolt/apsrtable")
install.packages('apsrtable')
library(plm)
install.packages('plm')
library(plm)
fixed <- plm(y ~ x1, data=Panel, index=c("country", "year"), model="within")
summary(fixed)
fixedf(fixed) # Display the fixed effects (constants for each country)
pFtest(fixed, ols) # Testing for fixed effects, null: OLS better than fixed
fixef(fixed) # Display the fixed effects (constants for each country)
####---RADOM EFFECTS MODEL---####
random <- plm(y ~ x1, data=Panel, index=c("country", "year"), model="random")
summary(random)
# Setting as panel data (an alternative way to run the above model
Panel.set <- plm.data(Panel, index = c("country", "year"))
# Setting as panel data (an alternative way to run the above model
Panel.set <- plm.frame(Panel, index = c("country", "year"))
# Setting as panel data (an alternative way to run the above model
Panel.set <- pdata.frame(Panel, index = c("country", "year"))
# Random effects using panel setting (same output as above)
random.set <- plm(y ~ x1, data = Panel.set, model="random")
summary(random.set)
####---FIXED OR RADOM EFFECTS MODEL---####
phtest(fixed, random)
fixed <- plm(y ~ x1, data=Panel, index=c("country", "year"),
model="within")
fixed.time <- plm(y ~ x1 + factor(year), data=Panel, index=c("country", "year"), model="within")
summary(fixed.time)
# Regular OLS (pooling model) using plm
pool <- plm(y ~ x1, data=Panel, index=c("country", "year"), model="pooling")
summary(pool)
# Breusch-Pagan Lagrange Multiplier for random effects. Null is no panel effect (i.e. OLS better).
plmtest(pool, type=c("bp"))
Panel.set <- plm.data(Panel, index = c("country", "year"))
Panel.set <- pdata.frame(Panel, index = c("country", "year"))
library(tseries)
adf.test(Panel.set$y, k=2)
library(lmtest)
bptest(y ~ x1 + factor(country), data = Panel, studentize=F)
random <- plm(y ~ x1, data=Panel, index=c("country", "year"), model="random")
library(foreign)
Panel <- read.dta("http://dss.princeton.edu/training/Panel101.dta")
coplot(y ~ year|country, type="l", data=Panel) # Lines
coplott(y ~ year|country, type="b", data=Panel) # Points and lines
coplot(y ~ year|country, type="b", data=Panel) # Points and lines
library(car)
scatterplot(y~year|country, boxplots=FALSE, smooth=TRUE, reg.line=TRUE, data=Panel)
####---FIXED EFFECTS MODEL---####
library(gplots)
plotmeans(y ~ country, main="Heterogeineity across countries", data=Panel)
plotmeans(y ~ year, main="Heterogeineity across years", data=Panel)
fixed.dum <-lm(y ~ x1 + factor(country) - 1, data=Panel)
fixed.dum <-lm(y ~ x1 + factor(country) - 1, data=Panel)
summary(fixed.dum)
fixed.dum <-lm(y ~ x1 + factor(country), data=Panel)
summary(fixed.dum)
library(apsrtable) # no install
install.packages(apsrtable)
install.packages('apsrtable')
devtools::install_github("r-fsolt/apsrtable")
devtools::install_github("r-forge/apsrtable")
install.packages('apsrtable', repos = 'https://github.com/r-forge/apsrtable')
install.packages("/home/gnac/Téléchargements/apsrtable.tar.gz", repos = NULL, type = "source")
install.packages("home/gnac/Téléchargements/apsrtable.tar.gz", repos = NULL, type = "source")
install.packages("home/gnac/Téléchargements/apsrtable.tar.gz")
install.packages('apsrtable')
tinytex::install_tinytex()
if (!require("readr")) install.packages("readr")
credit_risk_dataset = read_csv("~/Applis/GMM3/Stat. Multi. Varié/project/credit_risk_dataset.csv")
summary(credit_risk_dataset)
# Supprimer toutes les lignes contenant au moins une valeur manquante
data_cleaned <- na.omit(credit_risk_dataset)
# Vérifier le résultat
print(dim(data_cleaned))
summary(data_cleaned)
# Suppression des valeurs aberrantes basées sur les quantiles
credit_data_clean <- data_cleaned %>%
filter(
person_age >= quantile(person_age, 0.01) & person_age <= quantile(person_age, 0.99),
person_income >= quantile(person_income, 0.01) & person_income <= quantile(person_income, 0.99),
person_emp_length >= quantile(person_emp_length, 0.01) & person_emp_length <= quantile(person_emp_length, 0.99),
loan_amnt >= quantile(loan_amnt, 0.01) & loan_amnt <= quantile(loan_amnt, 0.99),
loan_int_rate >= quantile(loan_int_rate, 0.01) & loan_int_rate <= quantile(loan_int_rate, 0.99),
loan_percent_income >= quantile(loan_percent_income, 0.01) & loan_percent_income <= quantile(loan_percent_income, 0.99),
cb_person_cred_hist_length >= quantile(cb_person_cred_hist_length, 0.01) & cb_person_cred_hist_length <= quantile(cb_person_cred_hist_length, 0.99)
)
# Suppression des valeurs aberrantes basées sur les quantiles
credit_data_clean <- data_cleaned
filter(
person_age >= quantile(person_age, 0.01) & person_age <= quantile(person_age, 0.99),
person_income >= quantile(person_income, 0.01) & person_income <= quantile(person_income, 0.99),
person_emp_length >= quantile(person_emp_length, 0.01) & person_emp_length <= quantile(person_emp_length, 0.99),
loan_amnt >= quantile(loan_amnt, 0.01) & loan_amnt <= quantile(loan_amnt, 0.99),
loan_int_rate >= quantile(loan_int_rate, 0.01) & loan_int_rate <= quantile(loan_int_rate, 0.99),
loan_percent_income >= quantile(loan_percent_income, 0.01) & loan_percent_income <= quantile(loan_percent_income, 0.99),
cb_person_cred_hist_length >= quantile(cb_person_cred_hist_length, 0.01) & cb_person_cred_hist_length <= quantile(cb_person_cred_hist_length, 0.99)
)
# Suppression des valeurs aberrantes basées sur les quantiles
credit_data_clean <- data_cleaned
[filter(
# Suppression des valeurs aberrantes basées sur les quantiles
credit_data_clean <- data_cleaned
(filter(
person_age >= quantile(person_age, 0.01) & person_age <= quantile(person_age, 0.99),
person_income >= quantile(person_income, 0.01) & person_income <= quantile(person_income, 0.99),
person_emp_length >= quantile(person_emp_length, 0.01) & person_emp_length <= quantile(person_emp_length, 0.99),
loan_amnt >= quantile(loan_amnt, 0.01) & loan_amnt <= quantile(loan_amnt, 0.99),
loan_int_rate >= quantile(loan_int_rate, 0.01) & loan_int_rate <= quantile(loan_int_rate, 0.99),
loan_percent_income >= quantile(loan_percent_income, 0.01) & loan_percent_income <= quantile(loan_percent_income, 0.99),
cb_person_cred_hist_length >= quantile(cb_person_cred_hist_length, 0.01) & cb_person_cred_hist_length <= quantile(cb_person_cred_hist_length, 0.99)
))
# Calcul des quantiles et de l'IQR
Q1 <- quantile(data_cleaned$person_age, 0.25, na.rm = TRUE)
Q3 <- quantile(data_cleaned$person_age, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Définir les seuils pour détecter les outliers
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
print(c(lower_bound, upper_bound))
print(c(lower_bound, upper_bound, IQR))
summary(person_emp_length)
summary(data_cleaned$person_emp_length)
# Suppression des lignes où l'âge est < à 18 et > 90
data_cleaned <- data_cleaned[data_cleaned$person_age >= 18 & data$person_age <= 90, ]
# Suppression des lignes où l'âge est < à 18 et > 90
data_cleaned <- data_cleaned[data_cleaned$person_age >= 18 & data_cleaned$person_age <= 90, ]
# Suppression des lignes où la durée de l'emploi est supérieure à l'âge
data_cleaned <- data_cleaned[data_cleaned$person_emp_length <= data_cleaned$person_age - 16, ]
summary(data_cleaned)
# Chargement de la bibliothèque nécessaire
if (!require("caret")) install.packages("caret")
if (!require("caret")) install.packages("caret")
if (!require("readr")) install.packages("readr")
credit_risk_dataset = read_csv("~/Applis/GMM3/Stat. Multi. Varié/project/credit_risk_dataset.csv")
summary(credit_risk_dataset)
# Supprimer toutes les lignes contenant au moins une valeur manquante
data_cleaned <- na.omit(credit_risk_dataset)
# Vérifier le résultat
print(dim(data_cleaned))
summary(data_cleaned)
# Suppression des lignes où l'âge est < à 18 et > 90
data_cleaned <- data_cleaned[data_cleaned$person_age >= 18 & data_cleaned$person_age <= 90, ]
# Suppression des lignes où la durée de l'emploi est supérieure à l'âge
credit_data_clean <- data_cleaned[data_cleaned$person_emp_length <= data_cleaned$person_age - 16, ]
summary(credit_data_clean)
if (!require("caret")) install.packages("caret")
# Transformation des variables catégorielles en facteurs
credit_data_clean$person_home_ownership <- as.factor(credit_data_clean$person_home_ownership)
credit_data_clean$loan_intent <- as.factor(credit_data_clean$loan_intent)
credit_data_clean$loan_grade <- as.factor(credit_data_clean$loan_grade)
credit_data_clean$cb_person_default_on_file <- as.factor(credit_data_clean$cb_person_default_on_file)
# Application de l'encodage one-hot
dummies <- dummyVars(~ person_home_ownership + loan_intent + loan_grade + cb_person_default_on_file, data = credit_data_clean)
credit_data_encoded <- predict(dummies, newdata = credit_data_clean)
# Combinaison des données encodées avec les variables numériques
credit_data <- cbind(credit_data_clean %>% select(-person_home_ownership, -loan_intent, -loan_grade, -cb_person_default_on_file), credit_data_encoded)
if (!require("dplyr")) install.packages("dplyr")
if (!require("dplyr")) install.packages("dplyr")
if (!require("caret")) install.packages("caret")
# Transformation des variables catégorielles en facteurs
credit_data_clean$person_home_ownership <- as.factor(credit_data_clean$person_home_ownership)
credit_data_clean$loan_intent <- as.factor(credit_data_clean$loan_intent)
credit_data_clean$loan_grade <- as.factor(credit_data_clean$loan_grade)
credit_data_clean$cb_person_default_on_file <- as.factor(credit_data_clean$cb_person_default_on_file)
# Application de l'encodage one-hot
dummies <- dummyVars(~ person_home_ownership + loan_intent + loan_grade + cb_person_default_on_file, data = credit_data_clean)
credit_data_encoded <- predict(dummies, newdata = credit_data_clean)
# Combinaison des données encodées avec les variables numériques
credit_data <- cbind(credit_data_clean %>% select(-person_home_ownership, -loan_intent, -loan_grade, -cb_person_default_on_file), credit_data_encoded)
summary(credit_data)
if (!require("corrplot")) install.packages("corrplot")
# Calcul de la matrice de corrélation
cor_matrix <- cor(credit_data)
# Visualisation de la matrice de corrélation
corrplot(cor_matrix, method = "circle")
if (!require("corrplot")) install.packages("corrplot")
# Calcul de la matrice de corrélation
cor_matrix <- cor(credit_data)
# Visualisation de la matrice de corrélation
corrplot(cor_matrix, method = "circle")
if (!require("corrplot")) install.packages("corrplot")
# Calcul de la matrice de corrélation
cor_matrix <- cor(credit_data)
# Visualisation de la matrice de corrélation
corrplot(cor_matrix, method = "circle")
print(cor_matrix)
# Modèle de régression multiple
modele <- lm(loan_status ~ ., data = credit_data_final)
# Modèle de régression multiple
modele <- lm(loan_status ~ ., data = credit_data)
# Résumé du modèle
summary(modele)
corrplot(cor_matrix, method = "circle")
?corrplot
cor_matrix['loan_status']
View(cor_matrix)
cor_matrix['loan_status',]
# Variables Quantitative
var_quanti <- c('person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_status', 'loan_percent_income', 'cb_person_cred_hist_length')
data <- credit_data[var_quanti]
# Calcul de la matrice de corrélation
cor_matrix <- cor(data)
# Visualisation de la matrice de corrélation
corrplot(cor_matrix, method = "circle")
# Modèle de régression multiple
modele <- lm(loan_status ~ ., data = data)
# Résumé du modèle
summary(modele)
install.packages("AriGaMyANNSVR")
setwd("~/Applis/GMM3/Stat. Multi. Varié/project")
